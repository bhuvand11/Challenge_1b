# Challenge 1B â€” Relevant Section Extraction from PDFs


---

## ğŸŒ Overview

This repository contains a Dockerized, offline-compatible solution for **Adobe India Hackathon Challenge 1B**, which involves extracting only the most relevant sections of a PDF in response to a provided query.

All components run fully offline using pretrained models and local inference, and the setup is compatible with **Linux AMD64** environments via Docker.

---

## âœï¸ Approach

### 1. Input Query

* The system begins with a query defined in `challenge1b_input.json`, which specifies what information to extract from the PDF.

### 2. Outline Extraction

* `outline_extractor.py` scans the PDF using `PyMuPDF` and extracts hierarchical sections based on layout, indentation, and font.

### 3. Semantic Matching

* `section_selector.py` embeds both the query and all extracted sections using the offline `sentence-transformers/all-MiniLM-L6-v2` model.
* Cosine similarity is used to find the top-k relevant matches.

### 4. Linguistic Enhancement

* `spaCy` is used for additional NLP preprocessing with the `en_core_web_sm` model, which is stored and linked offline.

### 5. Execution Pipeline

* The complete process is initiated by `main.py`, which loads the query, processes the PDF, selects relevant sections, and writes the final output JSON.

---

## ğŸ“¦ Libraries Used

* `PyMuPDF`
* `pandas`, `numpy`
* `sentence-transformers`
* `scikit-learn`
* `spaCy`
* `joblib`

---

## ğŸ¤– Models Used

* Sentence Embedding: `sentence-transformers/all-MiniLM-L6-v2`
* NLP Toolkit: `spaCy` with `en_core_web_sm` (manually linked inside Docker)
* Heading Detection: `models/heading_model_ensemble.joblib` (included for reuse or debugging â€” currently not invoked by default)

---

## ğŸ“‚ Folder Structure

```
Challenge_1b/
â”œâ”€â”€ main.py
â”œâ”€â”€ section_selector.py
â”œâ”€â”€ outline_extractor.py
â”œâ”€â”€ challenge1b_input.json
â”œâ”€â”€ input/                  # Input PDFs
â”‚   â””â”€â”€ sample.pdf
â”œâ”€â”€ output/                 # Output JSON with relevant sections
â”‚   â””â”€â”€ .keep               # Placeholder for Git tracking
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ all-MiniLM-L6-v2/   # Sentence transformer model
â”‚   â”œâ”€â”€ en_core_web_sm/     # Local spaCy model (v3.8.0)
â”‚   â””â”€â”€ heading_model_ensemble.joblib
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ³ Docker Instructions

### ğŸ”§ Build the Docker Image

```bash
docker build --platform linux/amd64 -t challenge1b-app .
```

### ğŸš€ Run the Container

```bash
docker run --rm \
  -v "$(pwd)/input":/app/input:ro \
  -v "$(pwd)/output":/app/output \
  --network none \
  challenge1b-app
```

---

## âœ… Output Format

* The result will be saved as a `.json` file in the `/output` folder.
* This JSON contains only the top-k sections semantically aligned to the query.

---

## ğŸ“ Notes

* Runs **fully offline**
* Compatible with **Linux AMD64**
* Pretrained models stored in `/models` and loaded directly in Docker
* spaCy model is linked manually using:

  ```dockerfile
  RUN python -m spacy link models/en_core_web_sm/en_core_web_sm-3.8.0 en_core_web_sm
  ```

